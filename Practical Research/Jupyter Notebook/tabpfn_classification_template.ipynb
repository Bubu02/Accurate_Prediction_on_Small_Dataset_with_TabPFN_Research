{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6cc075c",
   "metadata": {},
   "source": [
    "\n",
    "# üîç Tabular Classification Benchmark: TabPFN vs Baselines\n",
    "\n",
    "This notebook evaluates **TabPFN** against four popular tabular classification models:\n",
    "- AutoGluon\n",
    "- CatBoost\n",
    "- LightGBM\n",
    "- XGBoost\n",
    "\n",
    "### üìä Datasets:\n",
    "- **Heart Disease** dataset (starter)\n",
    "- Three additional benchmark datasets from the TabPFN paper (page 20).\n",
    "\n",
    "### ‚öôÔ∏è Features:\n",
    "- Toggle for preprocessing (on/off)\n",
    "- Uniform evaluation pipeline\n",
    "- Dataset-agnostic design: simply plug in your dataset (must have a target column).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra  # Import necessary library\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)  # Import necessary library\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os  # Import necessary library\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b1e42",
   "metadata": {},
   "source": [
    "## Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3409d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "import subprocess  # Import necessary library\n",
    "\n",
    "# List of packages to install\n",
    "packages = [\n",
    "    \"scikit-learn==1.5.2\",\n",
    "    \"tabpfn\",\n",
    "    \"catboost\",\n",
    "    \"xgboost\",\n",
    "    \"autogluon\",\n",
    "    \"datasets\",\n",
    "    \"--upgrade git+https://github.com/automl/TabPFN.git\",\n",
    "    \"ucimlrepo\"\n",
    "]\n",
    "\n",
    "# Store installation logs\n",
    "logs = []\n",
    "\n",
    "# Install packages with a progress bar\n",
    "for pkg in tqdm(packages, desc=\"Installing Packages\", unit=\"pkg\"):\n",
    "    log = subprocess.run([\"pip\", \"install\", pkg], capture_output=True, text=True)\n",
    "    logs.append(log.stdout + log.stderr)\n",
    "\n",
    "# Create a scrollable output box for installation logs\n",
    "scrollable_logs = \"<pre style='max-height: 300px; overflow-y: scroll; border: 1px solid #ccc; padding: 10px;'>\" \\\n",
    "                  + \"\\n\".join(logs) + \"</pre>\"\n",
    "\n",
    "display(HTML(scrollable_logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f12675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# !pip install --upgrade --force-reinstall --no-cache-dir tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "import pandas as pd  # Import necessary library\n",
    "import numpy as np  # Import necessary library\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt  # Import necessary library\n",
    "from tabpfn import TabPFNClassifier\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed189d",
   "metadata": {},
   "source": [
    "## Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f926650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "statlog_german_credit_data = fetch_ucirepo(id=144)\n",
    "\n",
    "X = statlog_german_credit_data.data.features\n",
    "y = statlog_german_credit_data.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c52c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab38e002",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940dfd5",
   "metadata": {},
   "source": [
    "### Convert all columns to numeric codes for TabPFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d01a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# Step 1: Encode all features (TabPFN expects integers)\n",
    "X_enc = X.copy()\n",
    "for col in X_enc.columns:\n",
    "    if not pd.api.types.is_numeric_dtype(X_enc[col]):\n",
    "        X_enc[col] = LabelEncoder().fit_transform(X_enc[col].astype(str))  # Train the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d67439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# Step 2: Encode target\n",
    "if isinstance(y, pd.DataFrame):\n",
    "    y_vec = y.iloc[:, 0]\n",
    "else:\n",
    "    y_vec = y\n",
    "if y_vec.dtype == \"object\" or str(y_vec.dtype).startswith(\"category\"):\n",
    "    y_enc = LabelEncoder().fit_transform(y_vec)  # Train the model on training data\n",
    "else:\n",
    "    y_enc = np.asarray(y_vec).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e409def",
   "metadata": {},
   "source": [
    "### Fit TabPFN and extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# Step 3: Fit TabPFN Classifier (use CUDA if available)\n",
    "clf = TabPFNClassifier(device=\"cuda\")\n",
    "clf.fit(X_enc.values, y_enc)  # Train the model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# ! pip install --upgrade tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "import tabpfn  # Import necessary library\n",
    "print(tabpfn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# Step 4: Use predict_proba() as proxy for embeddings  # Make predictions on test data\n",
    "X_tabpfn_embed = clf.predict_proba(X_enc.values)  # Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65415a3e",
   "metadata": {},
   "source": [
    "### Plot PCA comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b73654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "import seaborn as sns  # Import necessary library\n",
    "\n",
    "def create_tabpfn_style_plot(X_original, X_embedded, y, figsize=(12, 10)):\n",
    "    \"\"\"\n",
    "    Create an enhanced PCA comparison plot with improved visual styling\n",
    "    \"\"\"\n",
    "    # Set the style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler_orig = StandardScaler()\n",
    "    scaler_emb = StandardScaler()\n",
    "    X_original_scaled = scaler_orig.fit_transform(X_original)  # Train the model on training data\n",
    "    X_embedded_scaled = scaler_emb.fit_transform(X_embedded)  # Train the model on training data\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca_orig = PCA(n_components=2)\n",
    "    pca_emb = PCA(n_components=2)\n",
    "    X_pca_orig = pca_orig.fit_transform(X_original_scaled)  # Train the model on training data\n",
    "    X_pca_emb = pca_emb.fit_transform(X_embedded_scaled)  # Train the model on training data\n",
    "    \n",
    "    # Create figure with enhanced styling\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, facecolor='white')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    # Enhanced color palette with better contrast\n",
    "    colors = [\n",
    "        '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7',\n",
    "        '#DDA0DD', '#98D8C8', '#F7DC6F', '#BB8FCE', '#85C1E9'\n",
    "    ]\n",
    "    \n",
    "    unique_labels = np.unique(y)\n",
    "    \n",
    "    # Plot TabPFN Embeddings\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        mask = y == label\n",
    "        scatter1 = ax1.scatter(X_pca_emb[mask, 0], X_pca_emb[mask, 1], \n",
    "                              c=colors[i % len(colors)], alpha=0.8, s=60, \n",
    "                              edgecolors='white', linewidth=0.5, label=f'Class {label}')\n",
    "    \n",
    "    # Enhanced styling for first subplot\n",
    "    ax1.set_title('TabPFN Embeddings + PCA', fontsize=16, fontweight='bold', \n",
    "                  pad=20, color='#2C3E50')\n",
    "    ax1.set_xlabel('First Principal Component (PC1)', fontsize=13, fontweight='500', color='#34495E')\n",
    "    ax1.set_ylabel('Second Principal Component (PC2)', fontsize=13, fontweight='500', color='#34495E')\n",
    "    \n",
    "    # Grid and styling\n",
    "    ax1.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)\n",
    "    ax1.set_facecolor('#FAFAFA')\n",
    "    \n",
    "    # Enhanced spines\n",
    "    for spine in ax1.spines.values():\n",
    "        spine.set_color('#BDC3C7')\n",
    "        spine.set_linewidth(1.2)\n",
    "    \n",
    "    # Tick styling\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=11, colors='#34495E')\n",
    "    ax1.tick_params(axis='both', which='minor', labelsize=9, colors='#7F8C8D')\n",
    "    \n",
    "    # Add panel label\n",
    "    ax1.text(0.02, 0.98, 'A', transform=ax1.transAxes, fontsize=18, \n",
    "             fontweight='bold', va='top', ha='left', \n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Plot Original Features\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        mask = y == label\n",
    "        scatter2 = ax2.scatter(X_pca_orig[mask, 0], X_pca_orig[mask, 1], \n",
    "                              c=colors[i % len(colors)], alpha=0.8, s=60, \n",
    "                              edgecolors='white', linewidth=0.5, label=f'Class {label}')\n",
    "    \n",
    "    # Enhanced styling for second subplot\n",
    "    ax2.set_title('Original Features + PCA', fontsize=16, fontweight='bold', \n",
    "                  pad=20, color='#2C3E50')\n",
    "    ax2.set_xlabel('First Principal Component (PC1)', fontsize=13, fontweight='500', color='#34495E')\n",
    "    ax2.set_ylabel('Second Principal Component (PC2)', fontsize=13, fontweight='500', color='#34495E')\n",
    "    \n",
    "    # Grid and styling\n",
    "    ax2.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)\n",
    "    ax2.set_facecolor('#FAFAFA')\n",
    "    \n",
    "    # Enhanced spines\n",
    "    for spine in ax2.spines.values():\n",
    "        spine.set_color('#BDC3C7')\n",
    "        spine.set_linewidth(1.2)\n",
    "    \n",
    "    # Tick styling\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=11, colors='#34495E')\n",
    "    ax2.tick_params(axis='both', which='minor', labelsize=9, colors='#7F8C8D')\n",
    "    \n",
    "    # Add panel label\n",
    "    ax2.text(0.02, 0.98, 'B', transform=ax2.transAxes, fontsize=18, \n",
    "             fontweight='bold', va='top', ha='left',\n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add legend with enhanced styling\n",
    "    legend1 = ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', \n",
    "                        frameon=True, fancybox=True, shadow=True, \n",
    "                        fontsize=10, title='Classes', title_fontsize=11)\n",
    "    legend1.get_frame().set_facecolor('white')\n",
    "    legend1.get_frame().set_alpha(0.9)\n",
    "    \n",
    "    legend2 = ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', \n",
    "                        frameon=True, fancybox=True, shadow=True, \n",
    "                        fontsize=10, title='Classes', title_fontsize=11)\n",
    "    legend2.get_frame().set_facecolor('white')\n",
    "    legend2.get_frame().set_alpha(0.9)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.4, right=0.85)\n",
    "    \n",
    "    # Add a subtle border around the entire figure\n",
    "    fig.patch.set_edgecolor('#BDC3C7')\n",
    "    fig.patch.set_linewidth(2)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Enhanced variance explanation output\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä PCA VARIANCE EXPLANATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üîπ TabPFN Embeddings:\")\n",
    "    print(f\"   PC1: {pca_emb.explained_variance_ratio_[0]:.2%} | PC2: {pca_emb.explained_variance_ratio_[1]:.2%}\")\n",
    "    print(f\"   Total: {sum(pca_emb.explained_variance_ratio_[:2]):.2%}\")\n",
    "    print()\n",
    "    print(f\"üîπ Original Features:\")\n",
    "    print(f\"   PC1: {pca_orig.explained_variance_ratio_[0]:.2%} | PC2: {pca_orig.explained_variance_ratio_[1]:.2%}\")\n",
    "    print(f\"   Total: {sum(pca_orig.explained_variance_ratio_[:2]):.2%}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return fig, (ax1, ax2), (pca_orig, pca_emb)\n",
    "\n",
    "# Alternative version with dark theme\n",
    "def create_tabpfn_style_plot_dark(X_original, X_embedded, y, figsize=(12, 10)):\n",
    "    \"\"\"\n",
    "    Create a dark-themed PCA comparison plot\n",
    "    \"\"\"\n",
    "    # Set dark style\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler_orig = StandardScaler()\n",
    "    scaler_emb = StandardScaler()\n",
    "    X_original_scaled = scaler_orig.fit_transform(X_original)  # Train the model on training data\n",
    "    X_embedded_scaled = scaler_emb.fit_transform(X_embedded)  # Train the model on training data\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca_orig = PCA(n_components=2)\n",
    "    pca_emb = PCA(n_components=2)\n",
    "    X_pca_orig = pca_orig.fit_transform(X_original_scaled)  # Train the model on training data\n",
    "    X_pca_emb = pca_emb.fit_transform(X_embedded_scaled)  # Train the model on training data\n",
    "    \n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, facecolor='#1E1E1E')\n",
    "    \n",
    "    # Neon-inspired color palette\n",
    "    colors = [\n",
    "        '#FF0080', '#00FF80', '#0080FF', '#FF8000', '#8000FF',\n",
    "        '#00FFFF', '#FFFF00', '#FF0040', '#40FF00', '#4000FF'\n",
    "    ]\n",
    "    \n",
    "    unique_labels = np.unique(y)\n",
    "    \n",
    "    # Plot with glow effect\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        mask = y == label\n",
    "        # Add glow effect\n",
    "        ax1.scatter(X_pca_emb[mask, 0], X_pca_emb[mask, 1], \n",
    "                   c=colors[i % len(colors)], alpha=0.3, s=80, edgecolors='none')\n",
    "        ax1.scatter(X_pca_emb[mask, 0], X_pca_emb[mask, 1], \n",
    "                   c=colors[i % len(colors)], alpha=0.9, s=40, \n",
    "                   edgecolors='white', linewidth=0.5, label=f'Class {label}')\n",
    "    \n",
    "    ax1.set_title('TabPFN Embeddings + PCA', fontsize=16, fontweight='bold', \n",
    "                  pad=20, color='white')\n",
    "    ax1.set_xlabel('PC1', fontsize=13, color='#CCCCCC')\n",
    "    ax1.set_ylabel('PC2', fontsize=13, color='#CCCCCC')\n",
    "    ax1.grid(True, alpha=0.2, color='white')\n",
    "    ax1.set_facecolor('#0A0A0A')\n",
    "    \n",
    "    # Similar styling for second plot\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        mask = y == label\n",
    "        ax2.scatter(X_pca_orig[mask, 0], X_pca_orig[mask, 1], \n",
    "                   c=colors[i % len(colors)], alpha=0.3, s=80, edgecolors='none')\n",
    "        ax2.scatter(X_pca_orig[mask, 0], X_pca_orig[mask, 1], \n",
    "                   c=colors[i % len(colors)], alpha=0.9, s=40, \n",
    "                   edgecolors='white', linewidth=0.5, label=f'Class {label}')\n",
    "    \n",
    "    ax2.set_title('Original Features + PCA', fontsize=16, fontweight='bold', \n",
    "                  pad=20, color='white')\n",
    "    ax2.set_xlabel('PC1', fontsize=13, color='#CCCCCC')\n",
    "    ax2.set_ylabel('PC2', fontsize=13, color='#CCCCCC')\n",
    "    ax2.grid(True, alpha=0.2, color='white')\n",
    "    ax2.set_facecolor('#0A0A0A')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.show()\n",
    "    \n",
    "    return fig, (ax1, ax2), (pca_orig, pca_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f85805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# Step 6: Plot!\n",
    "create_tabpfn_style_plot(X_enc, X_tabpfn_embed, y_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44b2f99",
   "metadata": {},
   "source": [
    "While working with the TabPFN model, an error was encountered when attempting to extract embeddings using `clf.transform(X_enc.values)`. This resulted in an `AttributeError` because the `TabPFNClassifier` does not implement a `.transform()` method. Unlike typical scikit-learn models or some transformer-based models that expose intermediate representations, TabPFN focuses on end-to-end prediction and does not provide direct access to internal embeddings. To address this, a workaround was used by leveraging the model‚Äôs `predict_proba()` output as a proxy for embeddings. Although not true internal features, the probability vectors still reflect the model‚Äôs learned structure and were suitable for visualization via PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378896c",
   "metadata": {},
   "source": [
    "# **Compairing Different Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63777c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Load dataset (user must specify path and target column)\n",
    "import pandas as pd\n",
    "DATA_PATH = '/kaggle/input/your-dataset.csv'  # <-- Change this\n",
    "TARGET_COL = 'target'  # <-- Change this\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f'Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606cbe7",
   "metadata": {},
   "source": [
    "## **Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ab9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "import pandas as pd  # Import necessary library\n",
    "import numpy as np  # Import necessary library\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def preprocess_dataframe(df_2):\n",
    "    \"\"\"\n",
    "    Preprocesses a DataFrame by:\n",
    "    - Handling missing values\n",
    "    - Normalizing numerical features\n",
    "    - One-hot encoding categorical features\n",
    "    - Label encoding the target variable (if present)\n",
    "\n",
    "    Returns:\n",
    "        - Processed feature DataFrame X\n",
    "        - Processed target Series y (if 'target' column is present)\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate target if present\n",
    "    y_processed = None\n",
    "    if \"target\" in df_2.columns:\n",
    "        le = LabelEncoder()\n",
    "        y_processed = pd.Series(le.fit_transform(df_2[\"target\"]), name=\"target\")  # Train the model on training data\n",
    "        df_2 = df_2.drop(columns=[\"target\"])\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols = df_2.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "    numerical_cols = df_2.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "    # Define transformations\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # Create the preprocessor\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"num\", numeric_transformer, numerical_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    # Fit and transform\n",
    "    X_processed = preprocessor.fit_transform(df_2)  # Train the model on training data\n",
    "\n",
    "    # Get transformed column names\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    X_processed_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "    return X_processed_df, y_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# Example usage\n",
    "# Make sure 'df_2' is defined and has the correct format\n",
    "X_processed_df, y_processed_series = preprocess_dataframe(df_2)\n",
    "print(\"Preprocessing complete!\")\n",
    "X_processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fefccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "if y_processed_series is not None:\n",
    "    print(y_processed_series.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "import seaborn as sns  # Import necessary library\n",
    "import matplotlib.pyplot as plt  # Import necessary library\n",
    "\n",
    "x = df_2.target.value_counts()\n",
    "p  = sns.countplot(data=df_2, x='target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2831b3",
   "metadata": {},
   "source": [
    "## **Train-Test Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28932c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "from sklearn.model_selection import train_test_split  # Split dataset into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed_df, y_processed_series, test_size=0.33, random_state=42)  # Split dataset into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e0832",
   "metadata": {},
   "source": [
    "#### ***Distribution on Original Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b51ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "df_2.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34674407",
   "metadata": {},
   "source": [
    "#### ***Distribution on Processed Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c617cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "X_processed_df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ee543",
   "metadata": {},
   "source": [
    "## **Deffining Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec46936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "import pandas as pd  # Import necessary library\n",
    "import numpy as np  # Import necessary library\n",
    "import torch  # Import necessary library\n",
    "import matplotlib.pyplot as plt  # Import necessary library\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from tabpfn import TabPFNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Train and evaluate TabPFN\n",
    "y_pred = TabPFNClassifier(random_state=42).fit(X_train, y_train).predict_proba(X_test)  # Train the model on training data\n",
    "\n",
    "# Calculate ROC AUC (handles both binary and multiclass)\n",
    "score = roc_auc_score(y_test, y_pred if len(np.unique(y)) > 2 else y_pred[:, 1])\n",
    "print(f\"TabPFN ROC AUC: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# # Define models\n",
    "# models = [\n",
    "#     ('TabPFN', TabPFNClassifier(random_state=42)),\n",
    "#     ('RandomForest', RandomForestClassifier(random_state=42)),\n",
    "#     ('XGBoost', XGBClassifier(random_state=42)),\n",
    "#     ('CatBoost', CatBoostClassifier(random_state=42, verbose=0)),\n",
    "#     ('LightGBM', LGBMClassifier(random_state=42)),  # Adding LightGBM\n",
    "# ]\n",
    "\n",
    "# # Convert y to Series\n",
    "# y_series = pd.Series(y_train, name='target')\n",
    "\n",
    "# # Prepare training data\n",
    "# train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# # Fit AutoGluon\n",
    "# autogluon_model = TabularPredictor(label='target').fit(train_data)  # Train the model on training data\n",
    "\n",
    "# # Calculate scores\n",
    "# scoring = 'roc_auc_ovr' if len(np.unique(y)) > 2 else 'roc_auc'\n",
    "# scores = {name: cross_val_score(model, X_train, y_train, cv=5, scoring=scoring, n_jobs=1, verbose=1).mean()\n",
    "#           for name, model in models}\n",
    "\n",
    "# # Evaluate AutoGluon\n",
    "# autogluon_score = autogluon_model.evaluate(train_data)\n",
    "# scores['AutoGluon'] = autogluon_score.get(scoring, None)\n",
    "\n",
    "# # Plot results\n",
    "# df = pd.DataFrame(list(scores.items()), columns=['Model', 'ROC AUC'])\n",
    "# ax = df.plot(x='Model', y='ROC AUC', kind='bar', figsize=(10, 6))\n",
    "# ax.set_ylim(df['ROC AUC'].min() * 0.995, min(1.0, df['ROC AUC'].max() * 1.005))\n",
    "# ax.set_title('Model Comparison - 5-fold Cross-validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# Define classical models\n",
    "models = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=42)),\n",
    "    ('XGBoost', XGBClassifier(random_state=42)),\n",
    "    ('CatBoost', CatBoostClassifier(random_state=42, verbose=0)),\n",
    "    ('LightGBM', LGBMClassifier(random_state=42)),\n",
    "]\n",
    "\n",
    "# Scoring metric\n",
    "scoring = 'roc_auc_ovr' if len(np.unique(y_train)) > 2 else 'roc_auc'\n",
    "scores = {}\n",
    "\n",
    "# ---------------------- Classical Models ----------------------\n",
    "for name, model in models:\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=scoring, n_jobs=1, verbose=1).mean()\n",
    "    scores[name] = score\n",
    "\n",
    "# ---------------------- AutoGluon ----------------------\n",
    "train_data = X_train.copy()\n",
    "train_data['target'] = y_train.values\n",
    "\n",
    "test_data = X_test.copy()\n",
    "test_data['target'] = y_test.values\n",
    "\n",
    "autogluon_model = TabularPredictor(label='target').fit(train_data)  # Train the model on training data\n",
    "autogluon_score = autogluon_model.evaluate(test_data)\n",
    "scores['AutoGluon'] = autogluon_score.get(scoring, None)\n",
    "\n",
    "# ---------------------- TabPFN (Standard) ----------------------\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tabpfn_model = TabPFNClassifier(device=device)\n",
    "\n",
    "tabpfn_scores = []\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_train, y_train):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    tabpfn_model.fit(X_fold_train.values, y_fold_train)  # Train the model on training data\n",
    "    probas = tabpfn_model.predict_proba(X_fold_test.values)  # Make predictions on test data\n",
    "\n",
    "    if len(np.unique(y_train)) > 2:\n",
    "        auc = roc_auc_score(y_fold_test, probas, multi_class='ovr')\n",
    "    else:\n",
    "        auc = roc_auc_score(y_fold_test, probas[:, 1])\n",
    "    \n",
    "    tabpfn_scores.append(auc)\n",
    "\n",
    "scores['TabPFN'] = np.mean(tabpfn_scores)\n",
    "\n",
    "# ---------------------- TabPFN (PHE-style) ----------------------\n",
    "phe_scores = []\n",
    "for train_idx, test_idx in kf.split(X_train, y_train):\n",
    "    fold_aucs = []\n",
    "    for _ in range(3):  # simulate ensemble of 3 TabPFN models\n",
    "        phe_model = TabPFNClassifier(device=device)\n",
    "        phe_model.fit(X_train.iloc[train_idx].values, y_train.iloc[train_idx])  # Train the model on training data\n",
    "        probas = phe_model.predict_proba(X_train.iloc[test_idx].values)  # Make predictions on test data\n",
    "\n",
    "        if len(np.unique(y_train)) > 2:\n",
    "            auc = roc_auc_score(y_train.iloc[test_idx], probas, multi_class='ovr')\n",
    "        else:\n",
    "            auc = roc_auc_score(y_train.iloc[test_idx], probas[:, 1])\n",
    "        fold_aucs.append(auc)\n",
    "\n",
    "    phe_scores.append(np.mean(fold_aucs))\n",
    "\n",
    "scores['TabPFN (PHE)'] = np.mean(phe_scores)\n",
    "\n",
    "# ---------------------- Plot Results ----------------------\n",
    "df = pd.DataFrame(list(scores.items()), columns=['Model', 'ROC AUC'])\n",
    "ax = df.plot(x='Model', y='ROC AUC', kind='bar', figsize=(12, 6), color='teal')\n",
    "ax.set_ylim(df['ROC AUC'].min() * 0.995, min(1.0, df['ROC AUC'].max() * 1.005))\n",
    "ax.set_title('Model Comparison - 5-fold Cross-validation on Train Set')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1646c39b",
   "metadata": {},
   "source": [
    "## **AUC ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eeaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "def run_complete_analysis_with_tabpfn(X_train, y_train):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import time  # Import necessary library\n",
    "\n",
    "    results = []\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scoring = 'roc_auc_ovr' if len(np.unique(y_train)) > 2 else 'roc_auc'\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    models = [\n",
    "        ('RandomForest', RandomForestClassifier(random_state=42)),\n",
    "        ('XGBoost', XGBClassifier(random_state=42, eval_metric='logloss')),\n",
    "        ('CatBoost', CatBoostClassifier(random_state=42, verbose=0)),\n",
    "        ('LightGBM', LGBMClassifier(random_state=42, verbose=-1)),\n",
    "    ]\n",
    "\n",
    "    for name, model in models:\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        times, scores = [], []\n",
    "        for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            start_time = time.time()\n",
    "            model.fit(X_tr, y_tr)  # Train the model on training data\n",
    "            fit_time = time.time() - start_time  # Train the model on training data\n",
    "\n",
    "            start_time = time.time()\n",
    "            probs = model.predict_proba(X_val)  # Make predictions on test data\n",
    "            pred_time = time.time() - start_time\n",
    "\n",
    "            score = roc_auc_score(y_val, probs[:, 1] if probs.shape[1] == 2 else probs, multi_class='ovr')\n",
    "            scores.append(score)\n",
    "            times.append(fit_time + pred_time)  # Train the model on training data\n",
    "\n",
    "        results.append({\n",
    "            'model': name,\n",
    "            'avg_time': np.mean(times),\n",
    "            'roc_auc': np.mean(scores)\n",
    "        })\n",
    "\n",
    "    # --- AutoGluon ---\n",
    "    print(\"Evaluating AutoGluon...\")\n",
    "    train_df = X_train.copy()\n",
    "    train_df['target'] = y_train.values\n",
    "\n",
    "    start = time.time()\n",
    "    ag_model = TabularPredictor(label='target', verbosity=0).fit(train_df)  # Train the model on training data\n",
    "    fit_time = time.time() - start  # Train the model on training data\n",
    "\n",
    "    start = time.time()\n",
    "    preds = ag_model.predict_proba(X_train)  # Make predictions on test data\n",
    "    pred_time = time.time() - start\n",
    "\n",
    "    auc_score = roc_auc_score(y_train, preds.iloc[:, 1] if preds.shape[1] == 2 else preds, multi_class='ovr')\n",
    "\n",
    "    results.append({\n",
    "        'model': 'AutoGluon',\n",
    "        'avg_time': fit_time + pred_time,  # Train the model on training data\n",
    "        'roc_auc': auc_score\n",
    "    })\n",
    "\n",
    "    # --- TabPFN ---\n",
    "    print(\"Evaluating TabPFN...\")\n",
    "    tabpfn_times, tabpfn_scores = [], []\n",
    "    for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "        model = TabPFNClassifier(device=device)\n",
    "        X_tr, X_val = X_train.iloc[train_idx].values, X_train.iloc[val_idx].values\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        start = time.time()\n",
    "        model.fit(X_tr, y_tr)  # Train the model on training data\n",
    "        fit_time = time.time() - start  # Train the model on training data\n",
    "\n",
    "        start = time.time()\n",
    "        probs = model.predict_proba(X_val)  # Make predictions on test data\n",
    "        pred_time = time.time() - start\n",
    "\n",
    "        auc = roc_auc_score(y_val, probs[:, 1] if probs.shape[1] == 2 else probs, multi_class='ovr')\n",
    "        tabpfn_scores.append(auc)\n",
    "        tabpfn_times.append(fit_time + pred_time)  # Train the model on training data\n",
    "\n",
    "    results.append({\n",
    "        'model': 'TabPFN',\n",
    "        'avg_time': np.mean(tabpfn_times),\n",
    "        'roc_auc': np.mean(tabpfn_scores)\n",
    "    })\n",
    "\n",
    "    # --- TabPFN (PHE-style) ---\n",
    "    print(\"Evaluating TabPFN (PHE)...\")\n",
    "    phe_times, phe_scores = [], []\n",
    "    for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "        aucs = []\n",
    "        fold_time = 0\n",
    "        for _ in range(3):  # Simulate ensemble of 3\n",
    "            model = TabPFNClassifier(device=device)\n",
    "            X_tr, X_val = X_train.iloc[train_idx].values, X_train.iloc[val_idx].values\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            start = time.time()\n",
    "            model.fit(X_tr, y_tr)  # Train the model on training data\n",
    "            probs = model.predict_proba(X_val)  # Make predictions on test data\n",
    "            fold_time += time.time() - start\n",
    "\n",
    "            auc = roc_auc_score(y_val, probs[:, 1] if probs.shape[1] == 2 else probs, multi_class='ovr')\n",
    "            aucs.append(auc)\n",
    "\n",
    "        phe_scores.append(np.mean(aucs))\n",
    "        phe_times.append(fold_time)\n",
    "\n",
    "    results.append({\n",
    "        'model': 'TabPFN (PHE)',\n",
    "        'avg_time': np.mean(phe_times),\n",
    "        'roc_auc': np.mean(phe_scores)\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "def create_performance_time_plot_fixed(results_df):\n",
    "    \"\"\"\n",
    "    Create a plot showing normalized ROC AUC vs average fit + predict time  # Train the model on training data\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt  # Import necessary library\n",
    "    import numpy as np  # Import necessary library\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Define styles per model\n",
    "    model_styles = {\n",
    "        'TabPFN': {'color': '#2E8B57', 'marker': '*', 'size': 150, 'alpha': 0.3},\n",
    "        'TabPFN (PHE)': {'color': '#006400', 'marker': 'o', 'size': 100, 'alpha': 0.3},\n",
    "        'RandomForest': {'color': '#1E90FF', 'marker': 'o', 'size': 100, 'alpha': 0.3},\n",
    "        'XGBoost': {'color': '#8A2BE2', 'marker': 's', 'size': 100, 'alpha': 0.3},\n",
    "        'CatBoost': {'color': '#DC143C', 'marker': 'D', 'size': 100, 'alpha': 0.3},\n",
    "        'LightGBM': {'color': '#FF8C00', 'marker': '^', 'size': 100, 'alpha': 0.3},\n",
    "        'AutoGluon': {'color': '#4682B4', 'marker': 'v', 'size': 100, 'alpha': 0.3}\n",
    "    }\n",
    "    \n",
    "    # OPTION 1: Min-Max Normalization (recommended)\n",
    "    min_auc = results_df['roc_auc'].min()\n",
    "    max_auc = results_df['roc_auc'].max()\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        model_name = row['model']\n",
    "        style = model_styles.get(model_name, {'color': 'gray', 'marker': 'o', 'size': 100, 'alpha': 0.3})\n",
    "        \n",
    "        # Min-Max normalization\n",
    "        norm_auc = (row['roc_auc'] - min_auc) / (max_auc - min_auc)\n",
    "        \n",
    "        # Simulated confidence band\n",
    "        time_vals = np.logspace(np.log10(max(0.01, row['avg_time'] * 0.5)), \n",
    "                                np.log10(row['avg_time'] * 2), 50)\n",
    "        auc_vals = np.full_like(time_vals, norm_auc)\n",
    "        noise = np.random.normal(0, 0.02, len(time_vals))\n",
    "        auc_upper = np.clip(auc_vals + abs(noise), 0, 1)\n",
    "        auc_lower = np.clip(auc_vals - abs(noise), 0, 1)\n",
    "        \n",
    "        plt.fill_between(time_vals, auc_lower, auc_upper, \n",
    "                         color=style['color'], alpha=style['alpha'])\n",
    "        \n",
    "        plt.scatter(row['avg_time'], norm_auc,\n",
    "                    color=style['color'], marker=style['marker'],\n",
    "                    s=style['size'], label=model_name,\n",
    "                    edgecolors='black', linewidth=1, zorder=5)\n",
    "        \n",
    "        plt.plot([row['avg_time'], row['avg_time']],\n",
    "                 [plt.ylim()[0], norm_auc],\n",
    "                 color=style['color'], linestyle=':', alpha=0.7)\n",
    "    \n",
    "    plt.axvline(x=10, color='black', linestyle='--', alpha=0.7)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Average Fit + Predict Time (s)', fontsize=12)\n",
    "    plt.ylabel('Normalized ROC AUC', fontsize=12)\n",
    "    plt.title('Normalized ROC AUC vs Inference Time', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks([0.01, 0.1, 1, 10, 100], ['0.01', '0.1', '1', '10', '100'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "results_df = run_complete_analysis_with_tabpfn(X_train, y_train)\n",
    "create_performance_time_plot_fixed(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "def create_performance_time_plot_fixed(results_df):\n",
    "    \"\"\"\n",
    "    Create a plot showing normalized ROC AUC vs average fit + predict time  # Train the model on training data\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt  # Import necessary library\n",
    "    import numpy as np  # Import necessary library\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Define styles per model\n",
    "    model_styles = {\n",
    "        'TabPFN': {'color': '#2E8B57', 'marker': '*', 'size': 150, 'alpha': 0.3},\n",
    "        'TabPFN (PHE)': {'color': '#006400', 'marker': 'o', 'size': 100, 'alpha': 0.3},\n",
    "        'RandomForest': {'color': '#1E90FF', 'marker': 'o', 'size': 100, 'alpha': 0.3},\n",
    "        'XGBoost': {'color': '#8A2BE2', 'marker': 's', 'size': 100, 'alpha': 0.3},\n",
    "        'CatBoost': {'color': '#DC143C', 'marker': 'D', 'size': 100, 'alpha': 0.3},\n",
    "        'LightGBM': {'color': '#FF8C00', 'marker': '^', 'size': 100, 'alpha': 0.3},\n",
    "        'AutoGluon': {'color': '#4682B4', 'marker': 'v', 'size': 100, 'alpha': 0.3}\n",
    "    }\n",
    "    \n",
    "    # OPTION 1: Min-Max Normalization (recommended)\n",
    "    min_auc = results_df['roc_auc'].min()\n",
    "    max_auc = results_df['roc_auc'].max()\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        model_name = row['model']\n",
    "        style = model_styles.get(model_name, {'color': 'gray', 'marker': 'o', 'size': 100, 'alpha': 0.3})\n",
    "        \n",
    "        # Min-Max normalization\n",
    "        norm_auc = (row['roc_auc'] - min_auc) / (max_auc - min_auc)\n",
    "        \n",
    "        # Simulated confidence band\n",
    "        time_vals = np.logspace(np.log10(max(0.01, row['avg_time'] * 0.5)), \n",
    "                                np.log10(row['avg_time'] * 2), 50)\n",
    "        auc_vals = np.full_like(time_vals, norm_auc)\n",
    "        noise = np.random.normal(0, 0.02, len(time_vals))\n",
    "        auc_upper = np.clip(auc_vals + abs(noise), 0, 1)\n",
    "        auc_lower = np.clip(auc_vals - abs(noise), 0, 1)\n",
    "        \n",
    "        plt.fill_between(time_vals, auc_lower, auc_upper, \n",
    "                         color=style['color'], alpha=style['alpha'])\n",
    "        \n",
    "        plt.scatter(row['avg_time'], norm_auc,\n",
    "                    color=style['color'], marker=style['marker'],\n",
    "                    s=style['size'], label=model_name,\n",
    "                    edgecolors='black', linewidth=1, zorder=5)\n",
    "        \n",
    "        plt.plot([row['avg_time'], row['avg_time']],\n",
    "                 [plt.ylim()[0], norm_auc],\n",
    "                 color=style['color'], linestyle=':', alpha=0.7)\n",
    "    \n",
    "    plt.axvline(x=10, color='black', linestyle='--', alpha=0.7)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Average Fit + Predict Time (s)', fontsize=12)\n",
    "    plt.ylabel('Normalized ROC AUC', fontsize=12)\n",
    "    plt.title('Normalized ROC AUC vs Inference Time', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks([0.01, 0.1, 1, 10, 100], ['0.01', '0.1', '1', '10', '100'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ALTERNATIVE: Use raw ROC AUC values instead of normalization\n",
    "def create_performance_time_plot_raw(results_df):\n",
    "    \"\"\"\n",
    "    Create a plot showing raw ROC AUC vs average fit + predict time  # Train the model on training data\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt  # Import necessary library\n",
    "    import numpy as np  # Import necessary library\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Define styles per model\n",
    "    model_styles = {\n",
    "        'TabPFN': {'color': '#2E8B57', 'marker': '*', 'size': 150},\n",
    "        'TabPFN (PHE)': {'color': '#006400', 'marker': 'o', 'size': 100},\n",
    "        'RandomForest': {'color': '#1E90FF', 'marker': 'o', 'size': 100},\n",
    "        'XGBoost': {'color': '#8A2BE2', 'marker': 's', 'size': 100},\n",
    "        'CatBoost': {'color': '#DC143C', 'marker': 'D', 'size': 100},\n",
    "        'LightGBM': {'color': '#FF8C00', 'marker': '^', 'size': 100},\n",
    "        'AutoGluon': {'color': '#4682B4', 'marker': 'v', 'size': 100}\n",
    "    }\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        model_name = row['model']\n",
    "        style = model_styles.get(model_name, {'color': 'gray', 'marker': 'o', 'size': 100})\n",
    "        \n",
    "        plt.scatter(row['avg_time'], row['roc_auc'],\n",
    "                    color=style['color'], marker=style['marker'],\n",
    "                    s=style['size'], label=model_name,\n",
    "                    edgecolors='black', linewidth=1, alpha=0.8)\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Average Fit + Predict Time (s)', fontsize=12)\n",
    "    plt.ylabel('ROC AUC', fontsize=12)\n",
    "    plt.title('ROC AUC vs Inference Time', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01011333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "# Example usage:\n",
    "results_df = run_complete_analysis_with_tabpfn(X_train, y_train)\n",
    "create_performance_time_plot_fixed(results_df)  # Fixed normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed950e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Code with Comments ---\n",
    "create_performance_time_plot_raw(results_df)    # Raw values (cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61de753",
   "metadata": {},
   "source": [
    "## **Testing Models on Original Data**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
